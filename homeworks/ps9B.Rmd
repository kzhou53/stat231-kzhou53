---
title: "STAT 231: Problem Set 9B"
author: "Kim Zhou"
date: "due by 10 PM on Friday, May 14"
output:
  pdf_document: default
---

This homework assignment is designed to help you further ingest, practice, and expand upon the material covered in class over the past week(s).  You are encouraged to work with other students, but all code and text must be written by you, and you must indicate below who you discussed the assignment with (if anyone).  

Steps to proceed:

\begin{enumerate}
\item In RStudio, go to File > Open Project, navigate to the folder with the course-content repo, select the course-content project (course-content.Rproj), and click "Open" 
\item Pull the course-content repo (e.g. using the blue-ish down arrow in the Git tab in upper right window)
\item Copy ps9B.Rmd from the course repo to your repo (see page 6 of the GitHub Classroom Guide for Stat231 if needed)
\item Close the course-content repo project in RStudio
\item Open YOUR repo project in RStudio
\item In the ps9B.Rmd file in YOUR repo, replace "YOUR NAME HERE" with your name
\item Add in your responses, committing and pushing to YOUR repo in appropriate places along the way
\item Run "Knit PDF" 
\item Upload the pdf to Gradescope.  Don't forget to select which of your pages are associated with each problem.  \textit{You will not get credit for work on unassigned pages (e.g., if you only selected the first page but your solution spans two pages, you would lose points for any part on the second page that the grader can't see).} 
\end{enumerate}

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```


\newpage 
# If you discussed this assignment with any of your peers, please list who here:

> ANSWER:

\newpage
# 1. Ethics follow-up

(a) Thinking about the discussion you had with the first group you were with during class on Tuesday 5/4 (focused on either "Predicting Policing & Recidivism" or "Predicting Financial Risk"), did your perspective on, or understanding of, any of the questions shift?  If so, please describe.  If not, was there anything you found surprising in the resources or your first group discussion?

> ANSWER: My opinions did not change, but rather felt stronger after hearing that other group members had similar opinions. Additionally, I found myself agreeing with some of the reasons they listed to support their opinion/understanding. We discussed what was realistic in terms of making AI more equitable and that we didn't really think it would be possible to fairly apply AI and algorithms to policing/recidivism because it is based off of historically biased data. The surprise at how accurate the algorithm was compared to random people surveyed was a shared sentiment within both our group and the second group I was in.  

(b) Thinking about the discussion you had with the second group you were with during class on Tuesday 5/4 (focused on considering the use of algorithms in the college admissions process), did your perspective on, or understanding of, the use of algorithms in these contexts shift?  If not, was there anything you found surprising in the resources or your second group discussion?

> ANSWER: We had some really interesting conversations about whether we would want AI and algorithms in charge of deciding whether we got into college, a job, etc. Specifically within the academic context, we came up with a solution to incorporate algorithm into the college admission process without relying too much on it, while also saving time. This invovled using certain tests and other aspects of a student's application to generate a score based on how well their scores were, how important these scores are to the particular school, and factoring other potential factors such as access to prep materials, household income, etc. This score would be one of the last things given to admissions officers so it does not have an overwhelming influence beforehand, but it could help make difficult decisions easier. 
 


\newpage

**CHOOSE ONE OF 2 (Clustering), 3 (Simulations) or 4 (SQL) to COMPLETE**

# 2. Clustering
## MDSR Exercise 9.5

Baseball players are voted into the Hall of Fame by the members of the Baseball Writers of America Association.  Quantitative criteria are used by the voters, but they are also allowed wide discretion.  The following code identifies the position players who have been elected to the Hall of Fame and tabulates a few basic statistics, include their number of career hits (`tH`), home runs (`tHR`), runs batted in (`tRBI`), and stolen bases (`tSB`).  Use the `kmeans()` function to perform a cluster analysis on these players.  Describe the properties that seem common to each cluster.

*Don't forget to standardize the variables before clustering, if applicable.*

> ANSWER: The green cluster of players appears to have the lowest total careere hits, home runs, and runs batted in. This makes some sense since batting less frequently means worse odds in hitting runs. Additionally, we see the purple and yellowish clusters have the highest career hits, but the yellowish cluster also has some of the lowest home runs while purple is well spread. Instead, we see that yellowish do have some of the higher bases stolen so these must be the players that are very fast rather than the best at batting. Finally, we see that the red cluster have high numbers of runs batted in. This could indicate that these players played for a longer time because they would have had the time to accumulate these numbers.

```{r, message = FALSE}
library(tidyverse)
library(mdsr)
library(Lahman)
library(GGally)

##### PLEASE DO NOT CHANGE THIS SEED NUMBER
##### keep set.seed(75) 
set.seed(75)

hof <- Batting %>%
  group_by(playerID) %>%
  inner_join(HallOfFame, by = "playerID") %>%
  filter(inducted == "Y" & votedBy == "BBWAA") %>%
  summarize(tH = sum(H), tHR = sum(HR), tRBI = sum(RBI), tSB = sum(SB)) %>%
  filter(tH > 1000)

bball_samp <- hof %>% 
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  sample_n(20)

vars <- c("tH", "tHR", "tRBI", "tSB")
km_out <- kmeans(bball_samp[,vars], centers = 5, nstart = 20)

bball_samp_clust <- bball_samp %>%
  mutate(clust = as.character(km_out$cluster))

ggpairs(data = bball_samp_clust
        , aes(color = clust) 
        , columns = vars
        , upper = list(continuous = "blank"))
```


\newpage

**CHOOSE ONE OF 2 (Clustering), 3 (Simulations) or 4 (SQL) to COMPLETE**

# 3. Simulation
## MDSR Exercise 10.6 (modified) 

\textit{Equal variance assumption}:  What is the impact of the violation of the equal variance assumption for linear regression models?  Repeatedly generate data from two "true" models:

(1) where the equal variance assumption is met: $y_i$ ~ $N(\mu_i, \sigma)$
(2) where the equal variance assumption is violated: $y_i$ ~ $N(\mu_i, \sigma_i)$

, where $\mu_i = -1 + 0.5*X_{1i} + 1.5*X_{2i}$, $\sigma$=1 in (1), $\sigma_i=1+X_{2i}$ in (2), and $X_1$ is a binary predicator and $X_2$ is Uniform(0,5).

Code to get you started is given below.  (Note that in (2) the standard deviation is dependent upon x2, which is random; i.e., the equal variance assumption is violated.  The Ys are *not* generated from a distribution with the same variance in (2).)

For each simulation, fit the linear regression model and display the distribution of 1,000 estimates of the $\beta_1$ parameter.  Does the distribution of the parameter follow a normal distribution in both cases?  Is it centered around $\beta_1$?  How does the variability in the distributions compare (variance in $\hat{\beta}_1$ when the equal variance assumption is met vs. when it is violated)?

> ANSWER:   

```{r}
library(tidyverse)

# number of observations in each sample
n_obs <- 250

rmse <- 1
x1 <- rep(c(0,1), each=n_obs/2)
x2 <- runif(n_obs, min=0, max=5)
beta0 <- -1
beta1 <- 0.5
beta2 <- 1.5

# for scenario 1, where equal var assumption is met (sd is constant value, rmse)
y1 <- beta0 + beta1*x1 + beta2*x2 + rnorm(n=n_obs, mean=0, sd=rmse)
# for scenario 2, where equal var assumption is violated (sd depends on x2)
y2 <- beta0 + beta1*x1 + beta2*x2 + rnorm(n=n_obs, mean=0, sd=rmse + x2)
  
# for scenario 1
mod1 <- lm(y1 ~ x1 + x2)
# for scenario 2
mod2 <- lm(y2 ~ x1 + x2)

summary(mod1)$coeff["x1","Estimate"]

# repeatedly generate data, fit the model, and extra the beta1 coefficient (1,000 times)
# number of simulations
n_sim <- 1000

# target visualization: sampling distribution of \hat{beta}_1
#                 (histogram or density plot of \beta_1 estimates), by scenario
# target summary numbers: mean and sd/variance of beta_1 estimates, by scenario

# loop through iterations

# create target visualization

# create target summaries
```


\newpage

**CHOOSE ONE OF 2 (Clustering), 3 (Simulations) or 4 (SQL) to COMPLETE**

# 4. SQL
## Airline flights

4a. Identify what years of data are available in the `flights` table of the airlines database using SQL code.

> ANSWER: 

```{r,eval=TRUE}
library(RMySQL)
library(mdsr)
# dbConnect_scidb is accesible from the mdsr package
aircon <- dbConnect_scidb("airlines")

# can use SHOW and EXPLAIN commands to explore what tables are available
# through this connection, and what variables/fields are in each table
dbGetQuery(aircon, "SHOW TABLES")
dbGetQuery(aircon, "EXPLAIN airports")
# can view first few obs of a table to see what the fields look like 
dbGetQuery(aircon, "SELECT * 
                   FROM airports
                   LIMIT 0,5")
```

```{sql connection=aircon}

```

4b. How many domestic flights flew into Dallas-Fort Worth (DFW) on May 14, 2010?  Use SQL to compute this number. (You can use R code to check it, if you wish.) 

> ANSWER: 

```{sql connection=aircon}

```

4c.  *Among the flights that flew into Dallas-Fort Worth (DFW) on May 14, 2010*, compute (using SQL) the number of flights and the average arrival delay time for each airline carrier.  Among these flights, how many carriers had an average arrival delay of 60 minutes or longer?

> ANSWER: 

```{sql connection=aircon}

```

